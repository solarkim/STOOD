{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","\n","import torch\n","from torchvision.models.feature_extraction import get_graph_node_names\n","from models import get_model\n","\n","def get_node_names(model):\n","    node_names = []\n","\n","    for name, _ in model.named_modules():\n","        if '.' in name:\n","            node_names.append(name)\n","\n","    return node_names"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## pyTorch 기본 모델 분석"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["['x',\n"," 'conv1',\n"," 'bn1',\n"," 'relu',\n"," 'maxpool',\n"," 'layer1.0.conv1',\n"," 'layer1.0.bn1',\n"," 'layer1.0.relu',\n"," 'layer1.0.conv2',\n"," 'layer1.0.bn2',\n"," 'layer1.0.relu_1',\n"," 'layer1.0.conv3',\n"," 'layer1.0.bn3',\n"," 'layer1.0.downsample.0',\n"," 'layer1.0.downsample.1',\n"," 'layer1.0.add',\n"," 'layer1.0.relu_2',\n"," 'layer1.1.conv1',\n"," 'layer1.1.bn1',\n"," 'layer1.1.relu',\n"," 'layer1.1.conv2',\n"," 'layer1.1.bn2',\n"," 'layer1.1.relu_1',\n"," 'layer1.1.conv3',\n"," 'layer1.1.bn3',\n"," 'layer1.1.add',\n"," 'layer1.1.relu_2',\n"," 'layer1.2.conv1',\n"," 'layer1.2.bn1',\n"," 'layer1.2.relu',\n"," 'layer1.2.conv2',\n"," 'layer1.2.bn2',\n"," 'layer1.2.relu_1',\n"," 'layer1.2.conv3',\n"," 'layer1.2.bn3',\n"," 'layer1.2.add',\n"," 'layer1.2.relu_2',\n"," 'layer2.0.conv1',\n"," 'layer2.0.bn1',\n"," 'layer2.0.relu',\n"," 'layer2.0.conv2',\n"," 'layer2.0.bn2',\n"," 'layer2.0.relu_1',\n"," 'layer2.0.conv3',\n"," 'layer2.0.bn3',\n"," 'layer2.0.downsample.0',\n"," 'layer2.0.downsample.1',\n"," 'layer2.0.add',\n"," 'layer2.0.relu_2',\n"," 'layer2.1.conv1',\n"," 'layer2.1.bn1',\n"," 'layer2.1.relu',\n"," 'layer2.1.conv2',\n"," 'layer2.1.bn2',\n"," 'layer2.1.relu_1',\n"," 'layer2.1.conv3',\n"," 'layer2.1.bn3',\n"," 'layer2.1.add',\n"," 'layer2.1.relu_2',\n"," 'layer2.2.conv1',\n"," 'layer2.2.bn1',\n"," 'layer2.2.relu',\n"," 'layer2.2.conv2',\n"," 'layer2.2.bn2',\n"," 'layer2.2.relu_1',\n"," 'layer2.2.conv3',\n"," 'layer2.2.bn3',\n"," 'layer2.2.add',\n"," 'layer2.2.relu_2',\n"," 'layer2.3.conv1',\n"," 'layer2.3.bn1',\n"," 'layer2.3.relu',\n"," 'layer2.3.conv2',\n"," 'layer2.3.bn2',\n"," 'layer2.3.relu_1',\n"," 'layer2.3.conv3',\n"," 'layer2.3.bn3',\n"," 'layer2.3.add',\n"," 'layer2.3.relu_2',\n"," 'layer3.0.conv1',\n"," 'layer3.0.bn1',\n"," 'layer3.0.relu',\n"," 'layer3.0.conv2',\n"," 'layer3.0.bn2',\n"," 'layer3.0.relu_1',\n"," 'layer3.0.conv3',\n"," 'layer3.0.bn3',\n"," 'layer3.0.downsample.0',\n"," 'layer3.0.downsample.1',\n"," 'layer3.0.add',\n"," 'layer3.0.relu_2',\n"," 'layer3.1.conv1',\n"," 'layer3.1.bn1',\n"," 'layer3.1.relu',\n"," 'layer3.1.conv2',\n"," 'layer3.1.bn2',\n"," 'layer3.1.relu_1',\n"," 'layer3.1.conv3',\n"," 'layer3.1.bn3',\n"," 'layer3.1.add',\n"," 'layer3.1.relu_2',\n"," 'layer3.2.conv1',\n"," 'layer3.2.bn1',\n"," 'layer3.2.relu',\n"," 'layer3.2.conv2',\n"," 'layer3.2.bn2',\n"," 'layer3.2.relu_1',\n"," 'layer3.2.conv3',\n"," 'layer3.2.bn3',\n"," 'layer3.2.add',\n"," 'layer3.2.relu_2',\n"," 'layer3.3.conv1',\n"," 'layer3.3.bn1',\n"," 'layer3.3.relu',\n"," 'layer3.3.conv2',\n"," 'layer3.3.bn2',\n"," 'layer3.3.relu_1',\n"," 'layer3.3.conv3',\n"," 'layer3.3.bn3',\n"," 'layer3.3.add',\n"," 'layer3.3.relu_2',\n"," 'layer3.4.conv1',\n"," 'layer3.4.bn1',\n"," 'layer3.4.relu',\n"," 'layer3.4.conv2',\n"," 'layer3.4.bn2',\n"," 'layer3.4.relu_1',\n"," 'layer3.4.conv3',\n"," 'layer3.4.bn3',\n"," 'layer3.4.add',\n"," 'layer3.4.relu_2',\n"," 'layer3.5.conv1',\n"," 'layer3.5.bn1',\n"," 'layer3.5.relu',\n"," 'layer3.5.conv2',\n"," 'layer3.5.bn2',\n"," 'layer3.5.relu_1',\n"," 'layer3.5.conv3',\n"," 'layer3.5.bn3',\n"," 'layer3.5.add',\n"," 'layer3.5.relu_2',\n"," 'layer4.0.conv1',\n"," 'layer4.0.bn1',\n"," 'layer4.0.relu',\n"," 'layer4.0.conv2',\n"," 'layer4.0.bn2',\n"," 'layer4.0.relu_1',\n"," 'layer4.0.conv3',\n"," 'layer4.0.bn3',\n"," 'layer4.0.downsample.0',\n"," 'layer4.0.downsample.1',\n"," 'layer4.0.add',\n"," 'layer4.0.relu_2',\n"," 'layer4.1.conv1',\n"," 'layer4.1.bn1',\n"," 'layer4.1.relu',\n"," 'layer4.1.conv2',\n"," 'layer4.1.bn2',\n"," 'layer4.1.relu_1',\n"," 'layer4.1.conv3',\n"," 'layer4.1.bn3',\n"," 'layer4.1.add',\n"," 'layer4.1.relu_2',\n"," 'layer4.2.conv1',\n"," 'layer4.2.bn1',\n"," 'layer4.2.relu',\n"," 'layer4.2.conv2',\n"," 'layer4.2.bn2',\n"," 'layer4.2.relu_1',\n"," 'layer4.2.conv3',\n"," 'layer4.2.bn3',\n"," 'layer4.2.add',\n"," 'layer4.2.relu_2',\n"," 'avgpool',\n"," 'flatten',\n"," 'fc']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["model = get_model('resnet50')\n","train_nodes, eval_nodes = get_graph_node_names(model.model)\n","eval_nodes"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## HuggingFace 모델 분석"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- MS Resnet50"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n","- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([10, 2048]) in the model instantiated\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"]},{"data":{"text/plain":["ResNetForImageClassification(\n","  (resnet): ResNetModel(\n","    (embedder): ResNetEmbeddings(\n","      (embedder): ResNetConvLayer(\n","        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activation): ReLU()\n","      )\n","      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    )\n","    (encoder): ResNetEncoder(\n","      (stages): ModuleList(\n","        (0): ResNetStage(\n","          (layers): Sequential(\n","            (0): ResNetBottleNeckLayer(\n","              (shortcut): ResNetShortCut(\n","                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (1): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (2): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","          )\n","        )\n","        (1): ResNetStage(\n","          (layers): Sequential(\n","            (0): ResNetBottleNeckLayer(\n","              (shortcut): ResNetShortCut(\n","                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (1): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (2): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (3): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","          )\n","        )\n","        (2): ResNetStage(\n","          (layers): Sequential(\n","            (0): ResNetBottleNeckLayer(\n","              (shortcut): ResNetShortCut(\n","                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (1): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (2): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (3): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (4): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (5): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","          )\n","        )\n","        (3): ResNetStage(\n","          (layers): Sequential(\n","            (0): ResNetBottleNeckLayer(\n","              (shortcut): ResNetShortCut(\n","                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","              )\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (1): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","            (2): ResNetBottleNeckLayer(\n","              (shortcut): Identity()\n","              (layer): Sequential(\n","                (0): ResNetConvLayer(\n","                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (1): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): ReLU()\n","                )\n","                (2): ResNetConvLayer(\n","                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","                  (activation): Identity()\n","                )\n","              )\n","              (activation): ReLU()\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=2048, out_features=10, bias=True)\n","  )\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["model = get_model('ms_resnet50')\n","model.model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 2048, 1, 1])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","with torch.no_grad():\n","    outputs = model.model.base_model(model.example_input_array, output_hidden_states=True)\n","outputs.pooler_output.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- ViT16"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n","- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/project/work/venv/farms/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n"]},{"data":{"text/plain":["ViTForImageClassification(\n","  (vit): ViTModel(\n","    (embeddings): ViTEmbeddings(\n","      (patch_embeddings): ViTPatchEmbeddings(\n","        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","      )\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): ViTEncoder(\n","      (layer): ModuleList(\n","        (0): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (6): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (7): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (8): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (9): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (10): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (11): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model = get_model('vit16')\n","model.model"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 768])\n","tensor([[-3.9416e-01, -8.6115e-01,  8.1237e-01, -8.1887e-01,  1.4707e-01,\n","          7.6216e-01, -1.6560e+00,  6.2770e-01, -1.6068e+00, -8.5001e-01,\n","         -1.5637e+00,  1.0181e+00, -1.2752e+00, -1.4599e-01, -9.5680e-01,\n","          1.0760e+00, -9.8362e-01, -7.2553e-01, -4.9964e-01, -1.0735e-03,\n","          1.1142e+00,  1.0845e+00, -4.8157e-01, -1.1751e-01,  1.1771e+00,\n","         -9.3265e-01,  3.7546e-01,  1.2659e-03,  1.4208e-01, -2.6776e-01,\n","         -1.0716e+00,  1.9308e-02, -5.4390e-02, -8.4021e-01, -5.4229e-01,\n","         -6.0595e-02,  9.6812e-01, -9.7414e-02, -2.5784e-01,  1.5728e+00,\n","          7.7523e-01,  7.0383e-01, -2.8317e-01, -1.0824e+00, -5.2147e-01,\n","         -1.3175e+00, -7.6344e-01, -7.6244e-01, -2.2818e-01,  5.2672e-01,\n","         -4.7757e-01,  2.3694e-01,  2.8581e-01, -5.7927e-01, -8.5997e-02,\n","          8.4022e-01,  6.0622e-01, -5.0133e-01,  8.2126e-01, -3.9532e-01,\n","         -8.2799e-01, -1.0612e+00, -3.3004e-01,  1.3755e+00, -1.8610e-01,\n","          7.9786e-02, -7.4494e-01, -9.0708e-02, -8.3673e-01, -1.0481e-01,\n","         -1.2020e-01,  1.6570e+00,  6.2813e-02, -5.8415e-01,  7.1568e-01,\n","          1.0963e+00, -1.5405e-02, -4.0097e-01, -7.8271e-01, -7.5887e-02,\n","         -5.5491e-01, -3.9606e-01,  9.7409e-01, -3.9530e-01,  1.4933e+00,\n","          1.2678e+00, -4.9418e-02, -6.9718e-01,  3.6726e-02,  5.2402e-01,\n","          8.9574e-01,  1.1826e+00,  1.2708e+00, -1.6033e+00,  8.6840e-02,\n","          2.1823e-02, -2.0839e-01, -2.9705e-01,  1.6639e-01, -6.7335e-01,\n","          9.7862e-01, -8.0496e-01, -1.4929e+00,  5.3845e-01,  2.8410e-01,\n","          1.5917e-01, -4.2719e-01, -1.3312e+00,  1.1724e+00,  8.0780e-01,\n","          3.2082e-01, -1.5738e+00,  6.3306e-01,  5.9190e-01,  6.4029e-01,\n","          9.7967e-02,  5.6523e-01,  6.3857e-01, -8.3853e-01, -7.2882e-01,\n","         -9.9071e-01,  3.1028e-02,  8.0853e-01, -2.8517e-01, -3.6185e-01,\n","          1.5344e+00, -3.7186e-01,  2.2308e+00, -6.8504e-01,  1.2509e-01,\n","          7.3980e-02, -7.7147e-01, -6.0172e-01,  9.7811e-01, -3.1241e-01,\n","         -1.4401e+00,  5.0109e-01, -7.9853e-01,  1.6902e-01,  2.3275e+00,\n","         -1.5109e+00, -1.2635e-01,  6.7779e-01,  1.0080e+00,  5.4742e-01,\n","          1.3203e+00,  1.6055e+00,  2.0443e-01,  7.2821e-01,  2.7163e-01,\n","         -2.5832e-01, -4.2177e-02,  1.6800e+00,  3.3525e-01, -3.0264e-01,\n","          4.4219e-01,  1.7195e+00, -2.0915e-01,  6.5302e-01,  1.6830e-01,\n","         -6.0871e-01,  1.7183e-01, -7.1984e-01,  6.8065e-01,  3.1640e-06,\n","         -5.5315e-01, -2.4160e-01,  9.2638e-01, -3.0756e+00,  5.7743e-01,\n","          6.6546e-01, -4.4614e-01,  2.0435e+00, -1.3558e+00,  8.7396e-01,\n","          1.8787e-01, -7.9624e-01, -1.2641e-01,  3.3600e-01, -5.4073e-01,\n","         -3.4563e-01, -1.6954e+00, -1.3169e-01,  1.3433e+00, -4.6677e-01,\n","         -3.6050e-01,  1.2197e+00, -7.2600e-01, -1.2418e+00,  3.4918e-01,\n","         -1.3866e-02, -4.9861e-01, -1.8510e-01, -1.0171e+00, -5.6785e-01,\n","          1.1202e+00,  6.0029e-01,  3.9748e-01,  8.7262e-01, -5.2045e-01,\n","         -1.2710e-01, -6.6179e-01, -1.0220e+00, -9.0237e-02,  7.3055e-01,\n","          3.6089e-01, -8.6620e-01, -2.5023e-01,  1.2631e-01, -2.5133e-01,\n","          2.4434e+00, -2.3013e-02, -1.1753e+00,  5.5472e-01, -5.3666e-01,\n","         -7.2078e-01, -1.1829e-01,  1.5048e+00, -4.0982e-01,  8.5613e-01,\n","         -9.7153e-01,  2.5893e-02, -1.0826e+00,  1.5034e+00, -2.1648e-01,\n","          5.4914e-01,  7.6295e-01,  7.1601e-01, -1.6287e-03,  3.4419e-01,\n","          3.0687e-01,  2.2685e-02, -6.4332e-01, -3.7642e-01, -9.3938e-01,\n","         -1.3444e+00, -3.6013e-01, -1.7533e-01,  2.7313e-01,  2.6530e-01,\n","          1.9722e+00, -1.4565e+00, -7.7100e-01, -1.8341e+00, -8.6070e-01,\n","          3.6792e-01,  1.0003e+00, -5.2106e-01,  4.7527e-01,  3.2053e-01,\n","         -9.3541e-01,  1.2687e-01, -8.0795e-01,  8.8366e-01,  6.0015e-01,\n","          9.5344e-01, -1.1681e+00, -5.6941e-01, -2.5652e-01,  2.3195e+00,\n","          3.5895e-01, -2.8688e-01,  6.3271e-01,  9.5777e-01,  3.2955e-01,\n","          5.7966e-01,  1.9990e+00,  6.6548e-02, -7.2174e-01, -1.0317e+00,\n","          7.5603e-02,  1.0360e-01,  1.0825e+00,  1.4560e+00, -1.8979e+00,\n","         -4.6587e-01, -1.0907e+00,  8.5614e-01, -1.2658e+00, -5.6400e-01,\n","          5.5146e-01, -7.6624e-02,  8.5069e-01,  4.3823e-01, -6.7040e-02,\n","         -3.5233e-01,  8.8705e-03,  1.4413e-01, -4.6191e-02, -3.9915e-01,\n","         -6.6261e-02,  1.7569e+00,  1.9287e-02, -6.1912e-01,  2.6385e-01,\n","          2.4052e-01,  5.9517e-01, -8.9805e-01, -1.9513e+00,  1.0102e+00,\n","         -7.3768e-01,  2.9926e-01, -1.8368e-01, -1.3769e-01,  5.3618e-01,\n","         -4.0901e-01, -9.2153e-01,  4.2047e-01, -3.6854e-01, -8.3279e-01,\n","          1.4669e+00,  1.5303e-01,  4.4874e-01, -8.4336e-01,  9.3642e-01,\n","          9.5970e-02, -1.1977e-01,  1.2298e+00,  5.7986e-01, -3.5684e+00,\n","         -1.1606e+00,  1.3759e+00, -4.3095e-02,  2.0919e-02,  7.3358e-01,\n","         -1.7341e+00,  1.8870e+00, -2.3809e-02,  1.6208e-01, -6.0652e-01,\n","         -9.9157e-01, -8.1491e-01, -8.7954e-01,  6.9981e-01, -3.1671e-01,\n","          9.4445e-02, -4.7284e-01,  2.7804e-01,  1.8186e+00, -1.1939e+00,\n","         -9.7532e-01,  1.4788e-01, -2.1750e-01, -9.3015e-01, -2.2416e+00,\n","         -7.7499e-01,  1.8156e-01,  8.9010e-01, -2.7672e-01,  1.8955e+00,\n","         -5.5848e-01, -3.3171e-01, -1.1771e+00, -7.2324e-01, -1.8710e-01,\n","          6.0607e-01,  4.3891e-02,  3.8151e-01, -3.9751e-02,  1.2081e+00,\n","         -6.3174e-01,  1.0614e+00,  1.5169e-01,  1.1549e+00, -7.0211e-01,\n","          6.0167e-01,  3.9827e-01,  7.1357e-01, -1.0515e+00, -2.5991e-01,\n","          1.3521e+00, -2.3592e-01,  2.0351e-01,  3.5148e-01,  2.8720e-01,\n","         -9.3306e-01,  6.0839e-01,  8.2187e-01, -6.4310e-02,  1.1286e+00,\n","         -7.0230e-01,  4.6394e-01, -1.4827e-01, -2.1731e-01, -1.4279e+00,\n","         -1.0808e+00, -3.6569e-01,  5.9753e-02,  3.3873e-01,  1.2332e+00,\n","         -4.8270e-01,  1.9017e-02, -5.9044e-01, -7.5613e-01,  1.3225e+00,\n","         -3.5612e-01, -2.9384e-01,  3.6928e-01, -3.3314e-01,  6.5046e-01,\n","          2.7990e+00, -2.4703e-01, -2.0098e+00, -1.4965e+00, -1.2731e+00,\n","          7.8569e-01, -1.6375e+00, -4.2697e-02,  3.6792e-01,  1.4423e+00,\n","          1.1925e+00,  2.2638e-01,  5.7680e-02,  3.8647e-01,  7.2407e-01,\n","         -1.4267e+00,  1.4157e+00, -4.2379e-01,  1.4724e+00, -2.2986e-01,\n","          1.5030e-01, -2.2280e-01, -6.0243e-01, -4.1565e-01,  1.6764e-01,\n","         -4.4613e-01,  4.2530e-01, -1.1317e+00,  4.7152e-01, -1.3032e+00,\n","         -1.6045e-01,  6.4079e-01,  1.0683e+00,  2.4686e-02, -2.5986e-01,\n","         -9.3226e-01,  7.3794e-01,  3.8506e-01,  6.9544e-02,  2.3807e-01,\n","          7.7080e-01,  4.0177e-02,  1.2890e+00,  8.2553e-02,  2.6848e-01,\n","         -1.8031e-01, -4.1898e-01, -5.6699e-01,  2.5402e-01, -1.2497e+00,\n","         -1.0502e-01,  1.6503e-01,  5.4711e-01,  1.6961e+00,  4.6258e-01,\n","         -3.7788e-01,  6.1031e-01, -1.9131e-01,  1.0105e+00, -1.0324e+00,\n","          6.5298e-01, -2.5294e-01,  1.3523e-01, -9.2539e-01, -1.1423e+00,\n","         -3.7027e-01, -3.0615e-01, -1.5913e+00,  1.0247e-01, -1.6248e+00,\n","          1.1941e-02, -1.6411e+00, -8.0182e-01, -3.2823e-01, -6.5812e-02,\n","          1.8758e-01,  6.6447e-01, -3.8304e-01,  1.1157e+00, -7.1693e-01,\n","          4.8542e-01, -1.1271e+00, -4.0593e-01,  1.7352e-01,  3.7863e-01,\n","         -1.4231e-01, -2.7797e-01, -1.5480e+00, -5.5080e-01,  1.2915e-01,\n","          5.9146e-01, -1.3998e+00,  3.2995e-01,  1.2016e+00,  1.0345e+00,\n","         -1.5582e+00,  1.1186e+00, -9.1949e-01, -8.0914e-01,  6.4967e-01,\n","          6.2855e-01,  1.5276e+00, -1.5250e-01,  6.1411e-01,  5.2112e-02,\n","         -1.0727e+00, -1.1877e+00,  4.6261e-01,  6.0911e-01,  3.5439e-01,\n","         -5.3157e-01,  3.7732e-01, -8.9040e-01, -3.6027e-01,  5.7268e-01,\n","          7.0532e-01, -2.3263e+00, -1.1612e+00, -1.1799e+00, -1.3409e+00,\n","          6.4321e-01, -8.9792e-01,  1.4424e+00,  1.3049e+00, -2.0820e+00,\n","          2.6275e+00,  4.5088e-01,  9.4856e-02, -9.4232e-01, -1.6400e+00,\n","         -2.0524e-02,  1.9261e-01, -3.0514e-01, -5.1248e-01, -1.6947e+00,\n","         -2.3301e+00,  1.2637e-01, -2.0693e-01,  2.2694e-01,  4.5227e-01,\n","         -1.0099e+00,  6.9169e-01, -5.1754e-01, -1.6733e+00,  2.0527e-01,\n","          4.9742e-01,  1.0890e+00,  1.5683e+00, -3.6466e-01, -7.1810e-02,\n","         -4.7710e-01,  5.0226e-02, -8.7024e-01, -7.6697e-01,  5.9157e-01,\n","          9.1743e-02,  4.3696e-01, -2.7293e-01,  7.5105e-01, -8.0621e-01,\n","         -2.7279e-01,  1.2910e+00, -1.9702e-01, -3.7974e-01, -6.4370e-01,\n","         -4.7090e-01,  8.5471e-02, -1.3957e+00, -7.2652e-01,  2.6176e-01,\n","          6.8659e-01,  8.8515e-01, -1.6801e+00,  4.0859e-02, -6.3489e-01,\n","          1.9981e-01, -1.4649e+00, -4.5717e-01, -5.6732e-02, -6.1953e-01,\n","         -9.0817e-01,  9.8718e-01,  1.6328e+00, -9.2178e-01,  7.8127e-01,\n","         -1.6225e-01, -2.2418e+00,  1.0152e-01, -8.5052e-01, -3.7179e-01,\n","          7.4726e-01,  4.5253e-01, -2.9342e-01,  4.3563e-01,  6.2122e-02,\n","         -8.3685e-01,  2.0493e-01, -4.4957e-01,  1.0125e+00, -1.7700e+00,\n","         -1.7305e-01,  9.3214e-01,  4.5380e-01, -1.1606e+00,  5.7529e-01,\n","          8.8022e-01, -1.7795e-01,  1.4024e+00,  1.0745e-01, -2.4220e-01,\n","         -2.1567e-01,  3.5849e-01, -3.7716e-01, -8.2106e-02,  4.0842e-01,\n","         -1.0266e-01,  8.8965e-01, -1.6805e+00, -3.2006e-01,  4.3805e-02,\n","         -3.7036e-01, -1.2154e+00, -8.8787e-02,  3.0515e-01, -1.4810e+00,\n","         -2.1026e+00,  9.4777e-01,  1.9772e-01,  5.9952e-01,  6.3153e-01,\n","          1.0146e+00, -2.9045e-01, -5.5905e-02,  4.5974e-01, -1.4692e+00,\n","          2.9564e-01,  1.3705e-01, -1.1743e+00, -7.5607e-01,  3.3963e+00,\n","          1.0977e-01,  9.6055e-01,  5.2557e-01,  1.0570e+00,  1.3490e+00,\n","         -1.1162e+00, -4.2091e-01,  1.5021e+00, -2.6187e-01,  3.8454e-01,\n","          1.4008e+00,  2.3548e+00, -5.5483e-01,  5.3973e-01,  9.7633e-01,\n","         -3.6071e-01, -1.2726e+00, -7.3047e-01, -2.9157e-01,  2.5429e-01,\n","          1.6332e-01, -1.3707e-01,  7.4642e-01, -4.5208e-03, -1.4440e+00,\n","         -1.8380e-01,  1.3766e-01,  3.8936e-01, -1.2785e+00,  9.4842e-01,\n","         -2.1880e+00, -1.9661e-01, -9.3256e-01,  1.7425e+00,  3.6811e-01,\n","         -1.0682e-01, -1.9833e-01, -5.8711e-02, -5.6235e-02, -8.7929e-01,\n","         -1.7158e+00,  7.8548e-01,  1.2270e+00,  9.3558e-01,  8.2840e-01,\n","         -6.6866e-01, -2.8127e-03, -9.8628e-01,  2.4193e-01,  8.3160e-01,\n","         -3.4906e-01, -1.1049e-01,  2.1467e-01,  1.2467e+00,  1.3783e-01,\n","         -1.1224e+00,  1.7259e-01,  5.1877e-01,  1.3377e+00,  4.7494e-02,\n","         -5.7070e-01, -7.7724e-01, -9.2650e-01,  1.1273e+00,  1.3391e+00,\n","          1.3300e-01,  8.7755e-01, -6.8688e-02, -5.2844e-01,  3.3900e-02,\n","         -4.1902e-01,  4.5552e-01,  2.2565e+00,  2.8736e-01,  2.9915e-01,\n","          6.1227e-01, -4.5759e-01, -8.9485e-01,  4.9597e-01, -4.7968e-01,\n","          9.0253e-01, -1.8248e+00, -4.9163e-02, -2.7384e-01, -1.0275e+00,\n","         -1.2570e-01,  5.9530e-01,  8.6467e-01,  2.5730e-01, -1.4831e-01,\n","         -2.0641e-01,  4.1394e-01, -1.2376e-01, -9.2972e-01,  9.3982e-01,\n","         -5.3106e-01, -5.9881e-01,  2.5777e-01,  3.4378e-01,  1.5261e+00,\n","         -1.0323e+00, -2.8367e-01, -5.3962e-01, -2.7250e-01, -1.4839e+00,\n","         -5.7783e-02,  5.8684e-01, -5.0274e-01, -8.6852e-01,  2.3301e-01,\n","         -3.5620e-01, -8.7327e-01, -2.5700e-01,  8.4736e-01,  5.3603e-01,\n","          4.8697e-01, -3.6732e-01, -1.0033e+00, -3.1602e-02,  4.3796e-02,\n","          6.5485e-01, -2.1794e-01, -4.8016e-01, -5.3472e-01,  1.5463e+00,\n","          4.1232e-01,  5.9180e-02, -4.6898e-01]])\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","    outputs = model.model.base_model(model.example_input_array, output_hidden_states=True)\n","    hidden_states = outputs.hidden_states\n","print(outputs.last_hidden_state[:, 0,:].shape)\n","print(outputs.last_hidden_state[:, 0,:])    # [CLS] token is at index 0"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- deit16"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-patch16-224 and are newly initialized because the shapes did not match:\n","- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([10, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/project/work/venv/farms/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n","  warnings.warn(\n"]},{"data":{"text/plain":["ViTForImageClassification(\n","  (vit): ViTModel(\n","    (embeddings): ViTEmbeddings(\n","      (patch_embeddings): ViTPatchEmbeddings(\n","        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","      )\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): ViTEncoder(\n","      (layer): ModuleList(\n","        (0): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (6): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (7): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (8): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (9): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (10): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (11): ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["model = get_model('deit16')\n","model.model"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 768])\n","tensor([[-4.1362e-01, -2.3566e-01, -1.6842e-01,  2.4150e-01,  3.7727e-01,\n","          4.0036e-01, -1.9911e-01,  2.2879e-01,  1.8547e-01,  1.7879e-01,\n","          7.6214e-02,  2.4491e-01,  6.2432e-01, -3.6866e-01,  1.1163e-01,\n","          1.4406e-01,  9.6961e-02,  6.7247e-01,  1.4773e-01, -2.2477e-01,\n","         -1.6158e-01, -8.7985e-02,  1.0490e+00, -3.0650e-01,  7.7875e-01,\n","          5.3884e-02,  4.3531e-01, -1.8043e-01,  9.2140e-01, -4.9171e-03,\n","          5.4310e-01, -1.9963e-02, -5.2398e-01, -2.7369e-01,  4.8437e-01,\n","         -8.5049e-01,  5.3675e-01, -1.8170e-01,  4.7189e-01, -1.3445e-01,\n","         -1.8008e-01, -1.2907e-01, -2.6956e-01,  6.0644e-01, -3.0759e-01,\n","         -3.7427e-01,  2.5605e-01,  3.9832e-01, -1.2933e-02, -7.4581e-01,\n","         -1.2591e-01, -5.9723e-01,  1.2022e-01,  1.6797e-01,  8.8628e-02,\n","         -2.6627e-02,  8.5379e-01, -3.4380e-01,  5.9352e-01, -3.4835e-01,\n","         -2.2782e-01,  7.2224e-01,  1.0423e-01,  1.4847e-01, -8.2029e-01,\n","          8.7475e-02,  1.6057e-01, -5.2915e-01, -5.5825e-02,  1.0447e-03,\n","         -1.7328e-01, -2.6453e-01, -5.2954e-01,  8.8179e-01, -8.4749e-01,\n","         -2.1553e-01, -3.6035e-01,  4.2879e-01,  2.1693e-02,  7.3542e-01,\n","         -2.9627e-01, -2.9419e-01,  1.6857e-01,  6.5732e-01,  5.5266e-01,\n","         -7.7179e-02, -6.2840e-01, -2.9974e-01,  8.0050e-02,  4.1131e-02,\n","          2.2207e-01, -4.2175e-01,  5.1947e-02, -1.4556e-01, -2.2856e-01,\n","          7.7295e-01, -1.3672e-01,  3.1145e-01,  2.8357e-01, -3.7177e-01,\n","         -1.5442e-01,  2.2971e-02,  7.5486e-01, -1.6871e-01,  9.6988e-01,\n","         -2.5726e-01,  1.7374e-01, -5.5078e-02, -4.2172e-02,  2.8947e-01,\n","         -6.6336e-02, -8.7061e-01, -1.4133e-02, -9.8835e-01,  4.2149e-02,\n","          1.2153e+00, -1.0522e-01,  3.6281e-01,  1.8332e-01,  1.0375e-01,\n","          2.3026e-01,  6.5886e-01,  8.6288e-02, -6.2684e-01,  2.1071e-01,\n","         -4.6915e-02,  7.2793e-02,  6.8660e-01, -1.7765e-03, -3.7053e-01,\n","         -5.1997e-02,  1.4079e-01, -1.8621e-01, -2.6509e-01,  5.7668e-02,\n","          5.2555e-01, -2.4282e-01, -2.9847e-01,  8.9030e-02, -1.3656e+00,\n","          4.9398e-01,  6.0129e-01,  2.7183e-01, -2.3960e-01, -4.1195e-01,\n","          3.3351e-01,  6.6316e-01, -8.7097e-01, -1.7963e-01,  1.4679e-01,\n","          9.8396e-02,  7.9303e-01,  1.6229e-01,  6.3483e-01, -1.9156e-01,\n","         -4.4909e-01, -9.9950e-02,  2.3214e-01,  8.8408e-01,  1.7707e-01,\n","         -1.0647e-01, -4.8930e-01, -5.6558e-01, -1.1081e-01,  4.4559e-01,\n","         -5.8001e-01, -1.4325e-01,  1.0561e-01, -3.4064e-02, -4.6014e-01,\n","          2.5785e-02, -3.5562e-01,  2.5137e-01,  8.0202e-01,  4.8207e-01,\n","         -2.9016e-01,  2.0410e-01,  2.1215e-01, -5.9454e-01, -4.0096e-01,\n","         -7.0502e-01, -3.0918e-02, -4.0905e-01,  4.9224e-03, -3.4273e-01,\n","         -5.4320e-01, -6.0339e-02,  5.6275e-01, -9.1365e-01, -1.6690e-01,\n","         -2.3057e-01,  1.2674e-01,  1.4025e+00,  1.9397e-01, -5.3104e-01,\n","          3.0698e-01, -1.2167e-01, -1.4008e-01,  1.0010e-01, -4.2550e-01,\n","          2.8824e-01,  1.3585e-01,  2.2894e-01, -9.0914e-01, -6.0259e-01,\n","          6.1806e-01, -2.1927e-02, -4.7721e-01,  7.1312e-01, -3.6315e-01,\n","          1.0566e+00,  4.1885e-01, -6.9362e-02,  7.4301e-02, -4.5474e-01,\n","          2.8214e-01, -6.0877e-02, -4.4797e-01, -8.6230e-02, -3.2561e-01,\n","          3.9044e-01, -5.5074e-01,  3.6056e-01, -5.1021e-01,  2.3659e-02,\n","         -7.3696e-01, -2.4791e-01,  2.3863e-01, -6.6694e-01,  2.1382e-01,\n","          7.2136e-01, -3.5646e-01,  1.2403e-01, -3.5393e-01, -3.6390e-01,\n","         -3.0217e-01, -9.4826e-01,  1.5630e-01, -1.3388e-01,  1.5498e-01,\n","          5.5634e-01, -1.5291e-01, -1.0117e+00,  3.1529e-01, -5.1961e-01,\n","         -3.5191e-01, -1.0189e+00,  8.7425e-01, -2.2831e-01, -3.3551e-01,\n","          1.6350e+00,  6.6089e-01,  6.9373e-01,  1.2487e-01, -1.3994e-01,\n","          2.4805e-01, -3.2249e-01,  1.6358e-01,  2.2517e-01,  6.3132e-01,\n","         -1.0151e-01, -3.9899e-01,  9.8307e-02, -1.9944e-01, -3.9095e-01,\n","         -1.8267e-01,  4.0900e-01, -1.5032e-02,  5.0641e-01,  3.1456e-01,\n","          1.3400e-01, -6.4751e-02,  3.8499e-01,  1.6602e-01,  2.3483e-01,\n","         -3.6159e-02, -1.2069e-01,  4.8838e-01, -1.0455e-01, -2.6645e-02,\n","          2.9584e-01,  4.9691e-01, -2.8348e-02,  1.9886e-01,  3.8839e-01,\n","         -2.4458e-01, -3.6571e-01,  1.2157e-01, -4.3365e-01, -1.8313e-01,\n","         -2.9727e-01,  9.7598e-02, -7.8614e-04, -3.4614e-01, -2.9572e+00,\n","          3.3907e-01,  2.1546e-01,  3.7211e-02, -1.1290e-01,  5.2748e-01,\n","         -2.1896e-01,  8.4217e-01,  3.0709e-01, -2.0683e+00, -9.3098e-02,\n","          6.0190e-01, -5.1702e-01, -5.8772e-02, -3.1179e-01, -3.0924e-02,\n","          3.5357e-01,  2.3934e-01,  3.5922e-01,  2.3889e-01,  3.2961e-01,\n","          7.6662e-01, -8.9320e-01, -1.3717e-01,  4.5857e-01, -4.5993e-01,\n","         -1.1901e-01, -1.6841e-01, -1.4317e-01,  3.1521e-01, -7.0399e-01,\n","         -1.8416e-01, -8.0260e-02, -6.5319e-01,  2.8439e-01,  5.4745e-01,\n","          2.7678e-01,  6.8461e-02,  5.3659e-01,  1.4780e-01, -4.1039e-01,\n","          3.0237e-01, -3.9796e-01, -5.6506e-02, -1.4434e-01, -8.8190e-02,\n","         -2.7676e-01,  1.6790e+00,  3.6116e-01,  7.8468e-02, -3.9494e-01,\n","         -3.0829e-01, -7.6854e-01,  6.8044e-01, -4.9840e-01, -1.1606e-01,\n","         -2.0697e-01,  2.4275e-01,  1.8424e-01, -2.5561e-01, -7.0809e-02,\n","         -2.7617e-01, -5.1014e-01,  2.4257e-01, -1.8767e-01, -6.7139e-01,\n","          5.7628e-02,  5.6763e-01,  5.8366e-04,  8.1491e-03,  4.4843e-01,\n","         -4.9487e-01, -3.1242e-01,  2.6963e-01,  3.5691e-01,  4.2352e-01,\n","          2.2500e-01, -1.1586e-01, -9.2276e-02, -3.7036e-01,  5.2743e-01,\n","          3.9938e-01,  6.0471e-01, -2.9840e-01, -7.2038e-01,  1.8076e-01,\n","          6.4711e-01, -5.6882e-01,  1.3756e-01,  9.7142e-02, -4.1070e-01,\n","         -1.6834e-01, -7.1833e-01, -2.1591e-01,  1.1172e+00,  3.8982e-01,\n","         -9.3015e-01, -3.0130e-01,  1.5857e-01, -4.1524e-02,  4.1911e-01,\n","          2.2429e-01,  6.5601e-02,  3.9291e-01, -6.0934e-01,  6.6087e-01,\n","          2.5183e-01,  8.8657e-01,  8.9676e-01, -2.1413e-03,  1.6010e-01,\n","          3.5300e-01, -3.8915e-02,  5.1433e-01, -4.0716e-01, -1.0016e-01,\n","         -2.2428e-01,  9.3441e-02, -4.3384e-01,  2.6878e-02,  6.6021e-01,\n","          6.8023e-02, -3.3389e-01, -7.0808e-01, -4.7125e-01, -6.1594e-01,\n","         -2.1652e+00,  9.4797e-01,  3.0873e-01,  4.9114e-01, -3.2832e-02,\n","          7.4915e-01, -4.6753e-01,  9.5703e-02, -6.2621e-01,  2.6275e-01,\n","         -6.7743e-01,  7.7419e-01, -2.4358e-01, -8.3970e-02, -3.3065e-01,\n","          3.9572e-01,  4.8395e-01,  1.0566e+00, -7.4151e-02, -1.3285e-01,\n","          9.4652e-02,  3.5860e-01,  3.1565e-01,  6.7054e-01, -4.1280e-01,\n","          1.6812e-01,  3.3441e-01, -4.2827e-01,  7.5264e-01,  6.5047e-01,\n","          5.4510e-01,  4.9950e-01, -1.2569e-01, -3.4495e-01,  3.3844e-01,\n","          2.1814e-01, -3.4505e-02,  2.3429e-01, -6.5694e-01,  1.9731e-01,\n","          3.1817e-01, -1.9448e-01,  2.1762e-01, -3.2971e-02, -5.7409e-01,\n","          5.9911e-01,  1.2096e-01,  5.6945e-01,  6.8523e-01,  3.1653e-01,\n","         -5.5268e-01,  1.5041e-01, -3.6560e-01, -4.1085e-01,  1.4549e-01,\n","          4.4928e-01,  2.1196e-01,  9.0677e-01, -1.4574e+00, -1.5651e-01,\n","          4.3412e-01,  2.0670e-01, -5.3731e-02,  2.0026e-01,  1.5592e-01,\n","         -1.4520e+00,  4.3262e-01, -1.8999e-01,  6.7436e-02,  6.3869e-01,\n","          1.2386e-02,  2.4449e-01, -2.0209e-02, -5.2468e-01,  6.5441e-01,\n","         -1.6776e-01,  5.0634e-01, -3.9766e-01,  2.0830e-01, -4.9528e-01,\n","          5.5167e-01,  1.9638e-02,  1.9796e-02, -2.5795e-01, -3.6821e-01,\n","         -1.3059e-01, -2.4423e-01,  2.5863e-01, -2.8255e-01,  4.2178e-01,\n","          4.0422e-01, -2.4223e-01, -1.1770e-01,  4.8391e-01, -6.3846e-02,\n","          5.2040e-01, -3.2330e-01, -9.5992e-02, -4.6326e-01, -4.3951e-01,\n","         -3.6215e-01,  1.8694e-01,  1.7939e-01,  1.5200e-01, -3.0868e-01,\n","          6.9367e-01,  2.1285e-01, -4.1460e-01,  7.3161e-02,  2.7112e-02,\n","         -7.7303e-01,  3.6869e-02, -5.0095e-01,  3.9942e-01, -1.7266e-01,\n","          3.5371e-01,  1.0264e+00,  4.3419e-01, -4.6746e-01, -2.3529e-01,\n","         -4.5631e-01, -1.8739e-01, -6.2516e-02,  6.9876e-02,  9.5047e-01,\n","          1.9342e-01, -2.0851e-01, -2.1319e-01,  7.5379e-02,  8.0186e-02,\n","         -1.3748e-01, -1.8465e-01, -5.1705e-01,  6.2966e-01, -4.8576e-01,\n","          1.3551e-01,  1.8106e-01, -4.9602e-01, -2.1253e-02,  2.6712e-01,\n","          8.5320e-02,  1.1678e-01, -8.5347e-01,  2.4627e+00, -3.8635e-01,\n","          8.6033e-02, -1.8914e-01, -6.6678e-01,  1.7367e-01,  7.0805e-02,\n","         -1.4996e-01,  2.6332e-01,  1.8912e-01, -5.2343e-01, -3.8392e-01,\n","         -4.6589e-01, -4.8419e-02,  3.6424e-01,  6.5400e-01, -3.6191e-02,\n","          4.2496e-01, -4.8559e-01,  2.4619e-01,  2.1896e-01, -9.7645e-01,\n","         -5.6646e-01,  1.2001e-02, -3.8698e-02,  1.8045e-02, -3.8829e-01,\n","          6.0291e-01,  4.7748e-03,  1.4526e-01, -2.9832e-01, -1.5231e-01,\n","         -3.5529e-01, -2.7833e-01,  2.5339e-01, -2.0723e-01, -3.5194e-02,\n","         -6.6106e-01, -3.5633e-01, -1.4485e-01, -5.5555e-01,  1.7166e-01,\n","         -9.0800e-02,  2.6597e-01,  2.2651e-01, -2.0350e-01,  2.1338e-01,\n","          1.8732e-01, -2.1899e-01,  4.3859e-01, -1.4162e-01, -3.1971e-01,\n","         -2.9339e-01,  3.0490e-01,  6.9018e-01,  2.5126e-01,  1.9810e-02,\n","          1.6860e-01,  4.3621e-01,  9.3919e-01, -2.3353e-01, -7.0950e-02,\n","          3.0719e-01, -2.1314e-01, -1.3941e+00,  1.8413e-01, -7.1446e-01,\n","          3.2290e-01, -2.1236e-01,  2.8307e-01,  9.3098e-02, -1.4108e+00,\n","         -4.0044e-01, -8.1760e-01, -5.9798e-01,  4.2420e-02,  2.1911e-01,\n","         -8.0639e-02, -2.4225e-02,  1.0280e+00, -2.9731e-01, -7.0644e-01,\n","         -3.5531e-02,  1.3727e-01,  6.2842e-01,  8.6475e-02, -5.3718e-01,\n","         -3.5323e-01, -1.3339e-01,  7.8519e-01,  2.3054e-01,  6.7819e-01,\n","          3.2110e-01, -4.1216e-01,  5.2010e-01,  7.0142e-01,  9.7474e-02,\n","         -1.0372e-01, -3.5424e-01, -3.7447e-01,  3.1154e-01, -4.2447e-01,\n","         -5.8316e-01,  3.4374e-01,  2.9426e-02,  1.1498e-01, -2.1626e-01,\n","          3.5819e-01, -9.3035e-01,  9.6346e-02,  1.0574e-01, -1.5263e-01,\n","         -3.7697e-01,  9.8843e-01, -9.8032e-01,  1.4971e-01, -2.0370e-01,\n","         -4.8399e-01, -1.0647e-01,  3.9257e-01,  1.1388e-01, -9.2971e-01,\n","         -6.0068e-01,  2.8107e-01, -4.4614e-01, -4.3206e-01, -3.1593e-01,\n","         -7.9871e-02, -2.1870e-01,  3.7644e-01, -2.8322e-01,  3.4471e-01,\n","         -1.7838e-01, -5.4917e-02, -6.7843e-01,  2.3553e-01, -2.1732e-01,\n","         -4.0508e-01,  1.3458e-01,  2.4377e-02,  3.5137e-01,  3.1273e-01,\n","         -2.1689e-01, -6.7341e-02, -5.8442e-03,  9.0181e-02, -6.8441e-02,\n","          1.8478e-01,  2.7504e-01, -3.5164e-01, -2.5325e-02,  2.6797e-01,\n","         -2.5107e-01,  9.8974e-01,  6.8523e-02, -4.1011e-01, -8.7167e-01,\n","          3.9789e-01,  9.1337e-01, -3.4476e-01,  2.1774e-01, -4.9309e-01,\n","          5.3442e-02, -1.9147e-01,  6.2441e-02, -2.3678e-01,  4.7525e-01,\n","         -2.6742e-01,  1.7469e-01, -2.9532e-02,  2.1968e-01, -5.9409e-02,\n","         -6.7785e-01,  5.2830e-01,  1.0562e+00, -1.7827e-01,  7.9088e-02,\n","          5.3768e-02,  3.5565e-01, -9.6715e-01, -6.0503e-01, -8.3891e-01,\n","          5.3028e-01, -7.1152e-01, -3.2243e-01,  5.1618e-01, -1.9880e-01,\n","         -4.7545e-01, -1.3745e-02, -2.6741e-01,  2.8002e-01, -6.7379e-01,\n","         -2.1943e-02,  1.5114e-01,  2.0287e-02, -1.6847e-02, -1.2260e-01,\n","          9.4325e-02, -3.7329e-01,  4.4770e-01,  4.3983e-01,  1.9609e-01,\n","         -5.4828e-01, -5.7822e-01,  8.3460e-02]])\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","    outputs = model.model.base_model(model.example_input_array, output_hidden_states=True)\n","    hidden_states = outputs.hidden_states\n","print(outputs.last_hidden_state[:, 0, :].shape)\n","print(outputs.last_hidden_state[:, 0, :])    # [CLS] token is at index 0"]}],"metadata":{"kernelspec":{"display_name":"farms","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
